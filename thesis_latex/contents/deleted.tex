

	





\begin{lstlisting}[language=python]

class Perceptron(object):
"""Perceptron classifier.
Parameters
------------
eta : float
Learning rate (between 0.0 and 1.0)
n_iter : int
Passes over the training dataset.
random_state : int # Random number generator seed for random weight initialization.

Attributes
-----------
w_ : 1d-array
Weights after fitting.
errors_ : list
Number of misclassifications (updates) in each epoch.
"""
def __init__(self, eta=0.01, n_iter=50, random_state=1):
self.eta = eta
self.n_iter = n_iter
self.random_state = random_state

"""Fit training data.
Parameters
----------
X : {array-like}, shape = [n_samples, n_features]
Training vectors, where n_samples is the number of samples and
n_features is the number of features.
y : array-like, shape = [n_samples]
Target values.
Returns
-------
self : object
"""

def fit(self, X, y):

rgen = np.random.RandomState(self.random_state)
self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])
self.errors_ = []

for _ in range(self.n_iter):
errors = 0
for xi, target in zip(X, y):
update = self.eta * (target - self.predict(xi))
self.w_[1:] += update * xi
self.w_[0] += update
errors += int(update != 0.0)
self.errors_.append(errors)
return self

def net_input(self, X): """Calculate net input"""
return np.dot(X, self.w_[1:]) + self.w_[0]

def predict(self, X): """Return class label after unit step"""
return np.where(self.net_input(X) >= 0.0, 1, -1)
\end{lstlisting}


%########################################################################
% CHAP 1
%########################################################################

La recherche des extrema est liée au calcul différentiel, grâce notamment au théorème suivant.
\begin{theorem}
	
	Soit $I$  un intervalle ouvert et $f:  I\rightarrow \mathbb{R} $ dérivable. Si $f$ admet un extremum local en $a$ alors $f'(a) = 0$.
\end{theorem}
La réciproque de ce théorème est fausse comme le montre l'exemple de la fonction cube, dont la dérivée s'annule en $0$, mais qui ne possède pas d'extremum en ce point. En général, on étudie la fonction, et notamment le signe de $f'$ pour déterminer si $a$ est effectivement un extremum, et si c'est un maximum ou un minimum.
%reciproque

Pour les fonctions de plusieurs variables, on remplace la dérivée par la différentielle et on affine l'étude avec les dérivées partielles secondes. On a ainsi le résultat suivant.

\begin{theorem}
	
	Soit $f: \mathbb{R}^2\rightarrow \mathbb{R} $  et $a \in \mathbb{R}^2 $.
	\begin{itemize}
		\item Si $f$ est différentiable, et si $f$ admet extremum local en $a$, alors 
		$$
		\frac{\partial f}{\partial x}(a)=0 \quad et \quad \frac{\partial f}{\partial y}(a)=0.
		$$
		On dit alors que $a$ est un \textbf{point stationnaire} ou \textbf{point critique} de $a$.
		\item Si $f \in I^2$ et, si  $a$ est point stationnaire de $f$, on pose
		$$ 
		r = \frac{\partial^2 f}{\partial x^2 }(a), \quad
		s = \frac{\partial^2 f}{\partial x \partial y }(a), \quad
		t = \frac{\partial^2 f}{\partial y^2 }(a).
		$$
		On distingue les cas suivants
		\begin{enumerate}
			\item Si $rt-s^2 > 0$ et $r > 0,\ f$ admet un minimum relatif en $a$.
			\item Si $rt-s^2 > 0$ et $r < 0,\ f$ admet un maximum relatif en $a$.
			\item Si $rt-s^2 < 0,\ f$ n'admet pas maximum en $a$ on parle de \textbf{point col}, ou de \textbf{point selle}.
			\item Si $rt-s^2 = 0$, on ne peut pas conclure.	
		\end{enumerate} 
	\end{itemize}
\end{theorem}


\subsubsection{\textbf{Développement limité}}\label{sec:dev_lim}
En physique et en mathématiques, un développement limité (noté DL) d'une fonction en un point est une \textit{approximation polynomiale} de cette fonction au voisinage de ce point, c'est-à-dire l'écriture de cette fonction sous la forme de la somme d'une fonction polynomiale et d'un reste négligeable au voisinage du point considéré \cite{coulombeau2013math, benner2015numerical}.

Soit $f$ une fonction à valeurs réelles définie sur un intervalle $I$, et $x_0 \in I$. On dit que $f$ admet un développement limité d'ordre $n^2$ (abrégé par $DL_n$) en $x_0$, s'il existe $n + 1$ réels $a_0, a_1, \dots, a_n$  tels que la fonction ${\displaystyle R:I\to \mathbb {R} }$ définie par :
$${\displaystyle f(x)=a_{0}+a_{1}(x-x_{0})+a_{2}(x-x_{0})^{2}+\dots+a_{n}(x-x_{0})^{n}+R(x)=\sum _{i=0}^{n}a_{i}(x-x_{0})^{i}+R(x)}$$
vérifie : $R(x)$ tend vers $0$ lorsque $x$ tend vers $x_0$, et ce plus rapidement que le dernier terme de la somme, c'est-à-dire que :
$$
\lim _{{x\rightarrow x_{0}}}{\frac{R(x)}{(x-x_{0})^{n}}}=0. 
$$

La fonction reste $R(x)$ vérifiant ceci est notée $o((x – x0)^n)$ (selon la notation de Landau). On écrit donc :

$$
f(x)= \sum _{i=0}^{n}a_{i}(x-x_{0})^{i}+R(x) =\sum _{{i=0}}^{n}a_{i}(x-x_{0})^{i}+o((x-x_{0})^{n})
$$

%\begin{tabular}{r l}
%\( f(x)\) & \( =\sum _{i=0}^{n}a_{i}(x-x_{0})^{i}+R(x)\) \\
%& \(=\sum _{{i=0}}^{n}a_{i}(x-x_{0})^{i}+o((x-x_{0})^{n}) \)
%\end{tabular}

Il est fréquent d'écrire un développement limité en posant $x = x_0 + h$ on aura:

\begin{equation}\label{eq:dev_lim_h}
f(x_{0}+h)=\sum _{{i=0}}^{n}a_{i}h^{i}+o(h^{n})
\end{equation}


\paragraph*{Conséquences immédiates}
\begin{itemize}
	\item Si $f$ admet un $DL_0$ en $x_0$, alors $a_0 = f(x_0)$. \cite{coulombeau2013math}
	\item Si $f$ admet un $DL_n$ en $x_0$, alors elle admet un $DL_k$ en $x_0$ pour tout entier $k < n$ \cite{coulombeau2013math}.
	\item Une condition nécessaire et suffisante pour que f admette un $DL_n$ en $x_0$ est l'existence d'un polynôme $P$ tel que $f(x) = P(x) + o((x – x_0)^n)$ \cite{coulombeau2013math}. S'il existe un tel polynôme $P$, alors il en existe une infinité d'autres, mais un seul d'entre eux est de degré inférieur ou égal à $n$ : le reste de la division euclidienne de $P(X)$ par $(X – x_0)^{n+1}$. On l'appelle la partie régulière, ou partie principale, du $DL_n$ de $f$ en $x_0$. %On identifie parfois, par abus de langage, le $DL_n$ avec sa partie régulière.
\end{itemize}



Le théorème de Taylor-Young assure \cite{coulombeau2013math} qu'une fonction $f$ dérivable $n$ fois au point $x_0$ (avec ${\displaystyle n\geq 1}$ admet un $DL_n$ en ce point :

$$
{\displaystyle f(x)=f(x_{0})+f'(x_{0})(x-x_{0})+{\frac {f''(x_{0})}{2!}}(x-x_{0})^{2}+\dots +{\frac {f^{(n)}(x_{0})}{n!}}(x-x_{0})^{n}+o((x-x_{0})^{n})}
$$

soit en écriture abrégée
$$
f(x)=\sum _{{i=0}}^{n}{\frac  {f^{{(i)}}(x_{0})}{i!}}(x-x_{0})^{i}+o((x-x_{0})^{n})
$$

Le développement d'ordre $0$ en $x_0$ revient à écrire que $f$ est continue en $x_0$ :

$$
{\displaystyle f(x)=f(x_{0})+o((x-x_{0})^{0})=f(x_{0})+o(1)}
$$

Le développement limité d'ordre $1$  en $x_0$ revient à approcher une courbe par sa tangente en $x_0$ on parle aussi d'approximation affine :

\begin{equation}\label{eq:dev_lim_cont}
f(x)=f(x_{0})+f'(x_{0})\cdot (x-x_{0})+o(x-x_{0})
\end{equation}


%\subsubsection{Différentiabilité au sens de Fréchet} \label{sec:drv_frechet}
%Soient $E$ un espace vectoriel normé, $F$ un espace vectoriel topologique séparé, $f$ une application de $E$ dans $F$ et $a$ un point de $E$. On abandonne la notation des vecteurs par des flèches dans ce paragraphe.

%On dit que $f$ est différentiable en $a$ (au sens de Fréchet) s'il existe une application linéaire continue ${\displaystyle L:E\to f}$ telle que :
%$$
%	\forall h\in E\quad f(a+h)=f(a)+L(h)+o\left(\|h\|\right)
%$$
%ou, de manière équivalente :

%$$
%	\lim _{h\to 0}{\frac {f(a+h)-f(a)-L(h)}{\|h\|}}=0.
%$$

%Une telle application linéaire $L$ est alors unique.
%L’opérateur $L$ est appelé différentielle de Fréchet (ou F-différentielle, ou Fréchet-différentielle) de $f$ au point $a$, et $f$ est dite Fréchet-différentiable (ou différentiable, ou différentiable au sens de Fréchet) au point $a$. La différentielle de $f$ au point $a$ est souvent notée $Df(a)$, la notation
%$f'(a)$ est aussi utilisée.
%\subsubsection{Fonctions dérivables}







\subsubsection{\textbf{Hessienne}}
\paragraph*{Définition mathématique:}
Étant donnée une fonction ${f}$ à valeurs réelles

$${ f:\mathbb{R}^{n}\to \mathbb {R} ;(x_{1},...,x_{n})\mapsto f(x_{1},...,x_{n})}$$
dont toutes les dérivées partielles secondes existent, le coefficient d'indice ${ i,j}$ de la \textbf{matrice hessienne\footnote{En mathématiques, la matrice hessienne (ou simplement la hessienne) d'une fonction numérique $f$ est la matrice carrée, notée $H(f)$, de ses dérivées partielles secondes.}} ${H(f)}$ vaut ${H_{ij}(f)={\frac {\partial ^{2}f}{\partial x_{i}\partial x_{j}}}}$ \cite{jtshiman:2021}.\\
Autrement dit,
$$
{ H(f)={
		\begin{bmatrix}{
			\frac {\partial ^{2}f}{{\partial x_{1}}^{2}}}&{\frac {\partial ^{2}f}{\partial x_{1}\partial x_{2}}}&\cdots &{\frac {\partial ^{2}f}{\partial x_{1}\partial x_{n}}}\\
		{\frac {\partial ^{2}f}{\partial x_{2}\partial x_{1}}}&{\frac {\partial ^{2}f}{{\partial x_{2}}^{2}}}&\cdots &{\frac {\partial ^{2}f}{\partial x_{2}\partial x_{n}}}\\
		\vdots &\vdots &\ddots &\vdots \\
		{\frac {\partial ^{2}f}{\partial x_{n}\partial x_{1}}}&{\frac {\partial ^{2}f}{\partial x_{n}\partial x_{2}}}&\cdots &{\frac {\partial ^{2}f}{{\partial x_{n}}^{2}}}
		\end{bmatrix}}} .
$$

\paragraph*{Définition numérique:}
Supposons que $f : \mathbb{R}^{n} \to \mathbb{R}$ définie sur un ouvert $\mathcal{O} \in \mathbb{R}^{n}$. La fonction $f(x)$ est dite 2
fois continûment dérivable (au sens de Fréchet) si en tout $x \in \mathcal{O}$ on a

\begin{equation}
f(x + h) = f(x)+\nabla f(x)^Th + \frac{1}{2}h^T\nabla^2f(x)h+o(||h||^2)
\end{equation}
avec$\nabla f(x)\in \mathbb{R}^{n\times n}$ et où on a posé que le reste 
$ o(||h||^2) =||h|| \epsilon(h) \in \mathbb{R} $ avec 
$\lim\limits_{||h|| \to 0} \epsilon(h) = 0 $
La matrice carrée symétrique $\nabla^2 f(x)$ appelée \textbf{Hessien} de $f(x)$ en $x$ \cite{bierlaire2006introduction}. Remarque :

$$
\lim\limits_{||h|| \to h} \frac{o(||h||^2)}{||h||} = 0  \in \mathbb{R}
$$
La Hessienne s’adresse aux fonctions scalaires à variables vectorielles.
%---------------------------------------------------
%	JACOBIENNE
%---------------------------------------------------		

\subsubsection{\textbf{Jacobienne}}
\paragraph*{Définition mathématique:}
Soit F une fonction d'un ouvert de $\mathbb{R}^{n}$ à valeurs dans $\mathbb{R}^{m}$ ($F:\mathbb{R}^{n}\to \mathbb {R}^{m}$). Une telle fonction est définie par ses $m$ fonctions composantes à valeurs réelles :

$$ 
{ F:
	{\begin{pmatrix}
		x_{1}\\\vdots \\
		x_{n}
		\end{pmatrix}}
	\longmapsto 
	{\begin{pmatrix}
		f_{1}(x_{1},\dots ,x_{n})\\
		\vdots \\f_{m}(x_{1},\dots ,x_{n})
		\end{pmatrix}}}.
$$
Les dérivées partielles de ces fonctions en un point $M$, si elles existent, peuvent être rangées dans une matrice à $m$ lignes et $n$ colonnes \cite{jtshiman:2021}, appelée \textbf{matrice jacobienne\footnote{En analyse vectorielle, la matrice jacobienne est la matrice des dérivées partielles du premier ordre d'une fonction vectorielle en un point donné.}} de $F$ :
$$
J_{F}\left(M\right)={
	\begin{pmatrix}
	{\dfrac {\partial f_{1}}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{1}}{\partial x_{n}}}\\
	\vdots &\ddots &\vdots \\
	{\dfrac {\partial f_{m}}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{m}}{\partial x_{n}}}
	\end{pmatrix}}.
$$

La case sur la ligne $i$ et la colonne $j$ contient ${\displaystyle {\frac {\partial f_{i}}{\partial x_{j}}}}$ qui est la dérivée partielle de $f_i$ selon la variable $x_j$. Cette matrice est notée :

$${\displaystyle J_{F}\left(M\right),\qquad {\frac {\partial \left(f_{1},\ldots ,f_{m}\right)}{\partial \left(x_{1},\ldots ,x_{n}\right)}}\qquad {\text{ou}}\qquad {\frac {\mathrm {D} \left(f_{1},\ldots ,f_{m}\right)}{\mathrm {D} \left(x_{1},\ldots ,x_{n}\right)}}}$$

Pour $i = 1, … , m,$ la i-ème ligne de cette matrice est la transposée du vecteur \textbf{gradient} (voir le point \ref{sec:gradient}) au point $M$ de la fonction $f_i$, lorsque celui-ci existe. La matrice jacobienne est également la matrice de la différentielle de la fonction, lorsque celle-ci existe \cite{jtshiman:2021}.
\paragraph*{Définition numérique:}

Soit $f(x) : \mathbb{R}^n \to \mathbb{R}^m$ définie sur un ouvert $ \mathcal{O} \subset \mathbb{R} $. On dit que $f(x)$ est dérivable
(au sens de Fréchet) en $x$, si chacune des composantes $f_i(x)$ est dérivable  en $x$ \cite{bierlaire2006introduction}. On a alors

\begin{equation}
f(x + h) = f(x) + D_f (x)h + o(||h||)
\end{equation}
avec $D_f (x) \in  \mathbb{R}^{n \times m} $ et/où $ o(||h||)=||h|| \epsilon(h) \in \mathbb{R}^m $ avec $\lim\limits_{||h|| \to 0} \epsilon(h) = 0 $.
Remarque :
$$
\lim\limits_{||h|| \to h} \frac{o(||h||^2)}{||h||} = 0  \in \mathbb{R}
$$

Soient 
$x = 
\begin{bmatrix}
x_1 & x_2& \cdots & x_n
\end{bmatrix}^{T}
\in \mathbb{R}^n $ et $ 
f(x) = 
\begin{bmatrix}
f_1(x) & f_2(x)& \cdots & f_n(x)
\end{bmatrix}^{T} \in \mathbb{R}^m
$

$$
D_f\left(x\right)={
	\begin{bmatrix}
	{\dfrac {\partial f_{1}(x)}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{1}(x)}{\partial x_{n}}}\\
	\vdots &\ddots &\vdots \\
	{\dfrac {\partial f_{m}(x)}{\partial x_{1}}}&\cdots &{\dfrac {\partial f_{m}(x)}{\partial x_{n}}}
	\end{bmatrix}}
=
\begin{bmatrix}
\nabla f_1(x)^T \\ \nabla f_2(x)^T\\ \vdots \\ \nabla f_m(x)^T
\end{bmatrix}
\in  \mathbb{R}^{n \times m},
$$
La matrice $D_f (x) \in  \mathbb{R}^{n \times m} $ est appelée \textbf{Jacobienne} de f(x) en x.
La Jacobienne s’adresse aux fonctions vectorielles à variables vectorielles \cite{jtshiman:2021}.

\begin{description}
	\item[Note:] Lorsque $m=1$ (m : nombre des lignes), la Jacobienne est la même que le gradient car il s'agit d'une généralisation du gradient.
\end{description}





		

\subsection{Échantillonnage (statistique)} \label{sec:chantillonnage} % \& probabilité bayésienne}

%\subsubsection{Échantillonnage (statistique)}

En statistiques, l'échantillonnage est la sélection d'un sous-ensemble (un échantillon statistique ) d'individus au sein d'une population statistique pour estimer les caractéristiques de l'ensemble de la population. \\
Sur un échantillon, on peut calculer différents paramètres statistiques de position ou de dispersion issus de la statistique descriptive, de la même manière que l'on peut déterminer des paramètres statistiques d'une population par son recensement exhaustif \cite{sarndal2003model}.

On peut également déduire des propriétés de la population à partir de celles de l'échantillon par inférence statistique. D'après la loi des grands nombres, plus la taille de l'échantillon augmente, plus ses propriétés seront proches de celles de la population. En particulier, on peut estimer une probabilité sur les individus d'une population par la fréquence observée sur un échantillon si sa taille est suffisamment grande \cite{sarndal2003model, harrell2001regression}. 

Cette méthode présente plusieurs avantages : une étude restreinte sur une partie de la population, un moindre coût, une collecte des données plus rapide que si l'étude avait été réalisée sur l'ensemble de la population, la réalisation de contrôles destructifs, etc.
Un dataset assez large permettra ainsi  à une machine d'effectuer un bon apprentissage automatique sur cet ensemble de données constituant l'échantillon de la population a apprendre.

\begin{list}{$\triangleright$ }{On peut procéder de différentes manières pour collecter les données de l'échantillon, il existe en effet plusieurs méthodes d'échantillonnage \cite{sarndal2003model} :}
	%\textbf
	\item  \textbf{Échantillonnage aléatoire et simple }: le tirage des individus de l'échantillon est aléatoire, c'est-à-dire que chaque individu a la même probabilité d'être choisi, et simple, c'est-à-dire que les choix des différents individus sont réalisés indépendamment les uns des autres.
	%L'échantillonnage aléatoire simple peut être vulnérable aux erreurs d'échantillonnage car le caractère aléatoire de la sélection peut donner un échantillon qui ne reflète pas la composition de la population. 
	
	\item  \textbf{Échantillonnage systématique }: le premier individu est choisi de manière aléatoire, puis les suivants sont déterminés à intervalle régulier. Par exemple, dans un verger, on choisit au hasard le 7e pommier, puis les 27e, 47e, 67e, etc.
	
	\item  \textbf{Échantillonnage stratifié }: on subdivise la population en plusieurs parties avant de prendre l'échantillon1.
	
	\item \textbf{Échantillonnage par quotas }: la composition de l'échantillon doit être représentative de celle de la population selon certains critères jugés particulièrement importants. On utilise cette méthode pour réaliser les sondages d'opinions.
\end{list}


\subsubsection{\textbf{La collecte de données} }

La collecte de données est le processus de collecte et de mesure des informations sur des variables ciblées dans un système établi, qui permet ensuite de répondre aux questions pertinentes et d'évaluer les résultats.

\begin{list}{--}{Une bonne collecte de données implique :}
	\item Suivre le processus d'échantillonnage défini
	\item Garder les données dans l'ordre du temps
	\item Noter les commentaires et autres événements contextuels
	\item Enregistrement des non-réponses
\end{list}

\paragraph*{Erreur d'échantillonnage :}
Dans les statistiques, les erreurs d'échantillonnage se produisent lorsque les caractéristiques statistiques d'une population sont estimées à partir d'un sous-ensemble, ou échantillon, de cette population. Étant donné que l'échantillon n'inclut pas tous les membres de la population, les statistiques de l'échantillon (souvent appelées estimateurs), telles que les moyennes et les quartiles, diffèrent généralement des statistiques de l'ensemble de la population (appelées paramètres ). La différence entre la statistique d'échantillon et le paramètre de population est considérée comme l'erreur d'échantillonnage \cite{sarndal2003model}. 




%\subsubsection{Généralité sur l'analyse bayésienne}
%La statistique bayésienne est une théorie dans le domaine des statistiques basée sur l' interprétation bayésienne de la probabilité où la probabilité exprime un degré de croyance en un événement. Le degré de croyance peut être basé sur des connaissances antérieures sur l'événement, telles que les résultats d'expériences précédentes, ou sur des croyances personnelles sur l'événement. Cela diffère d'un certain nombre d'autres interprétations de la probabilité , telles que l' interprétation fréquentiste qui considère la probabilité comme la limite de la fréquence relative d'un événement après de nombreux essais [??].

%Les statistiques bayésiennes portent le nom de Thomas Bayes qui a formulé un cas spécifique du théorème de Bayes dans un article publié en 1763.



%\begin{thm}[Théorème de Bayes] Le théorème de Bayes est utilisé dans les méthodes bayésiennes pour mettre à jour les probabilités, qui sont des degrés de croyance, après avoir obtenu de nouvelles données. Compte tenu de deux événements $A$  et $B$, la probabilité conditionnelle de $A$ étant donné que $B$ est vrai s'exprime comme suit  :
%\begin{equation}
%\mathbb{P}(A|B) = \frac{\mathbb{P}(B|A) \mathbb{P}(A)}{\mathbb{P}(B)}
%\end{equation}

%\end{thm}

%où $\mathbb{P}(B) \ne 0$ Bien que le théorème de Bayes soit un résultat fondamental de la théorie des probabilités , il a une interprétation spécifique dans les statistiques bayésiennes \cite[][]{antoine2018apprentissage}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{\textbf{Les ingrédients d'apprentissage}}
Résoudre un problème d'apprentissage, c'est d'abord le comprendre, c'est-à-dire discuter longuement avec les experts, ou consulter les ouvrages, du domaine concerné pour identifier quelles sont les "entrées", les  "sorties" ou résultats désirés, les connaissances disponibles, les particularités des données, par exemple: valeurs manquantes, taux de bruit dans les mesures des attributs de description, proportions des classes, stationnarité ou pas de l'environnement.\\ 
C'est aussi réaliser un gros travail de \textit{préparation des données}: nettoyage, ré-organisation, enrichissement, intégration avec d'autres sources de données, etc. Ces étapes de compréhension du problème, de préparation des données, de mise au point du protocole d'apprentissage et des mesures d'évaluation des résultats, prennent, et de loin, la plus grande partie du temps pour (tenter de) résoudre un problème d'apprentissage \cite{antoine2018apprentissage}. 
Nous avons toujours tendance à largement sous-estimer ces étapes et à vouloir se concentrer uniquement sur la phase excitante de l'essai de méthodes d'apprentissage sur des données supposées bonnes à la consommation \cite{darlington2016regression}. 
%\subsubsection{Algorithme qui apprennent}



	La table suivante présente d'abord les qualités des différentes représentations des hypothèses en fonction des critères cités ci-dessus.


%\parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{rota}}} 
\begin{center}
	\begin{tabular}{l|cccccc}
		& \rotatebox[origin=c]{90}{Fonctions séparatrices}
		&  \rotatebox[origin=c]{90}{Distributions de probabilités}
		& \rotatebox[origin=c]{90}{Arbres de décision }
		& \rotatebox[origin=c]{90}{Hiérarchies de concepts}
		& \rotatebox[origin=c]{90}{Réseaux bayésiens } 
		& \rotatebox[origin=c]{90}{Chaînes de Markov}\\
		\hline
		
		Concept & $\surd$ &$\surd$ &$\surd$ &$\surd$ & --&-- \\
		Classes multiples &$\surd$ & $\surd$ &$\surd$ &$\surd$ &--&-- \\
		Ontologies & --&-- & $\surd$&$\surd$ & --&-- \\
		Régression &-- &$\surd$ & $\surd$&-- &-- &-- \\
		Évolutions temporelles &-- &$\surd$ &-- &-- &-- & $\surd$\\
		Apprentissage non supervisé & $\surd$ &$\surd$ &$\surd$ &$\surd$ &-- &-- \\
		Données continues & $\surd$ &$\surd$ &$\surd$ &-- &-- &$\surd$  \\
		Connaissances relationnelles  & & & & $\surd$  & $\surd$  &-- \\
		Degré de certitude &-- &$\surd$ &-- &-- &$\surd$ &$\surd$ \\
		Degré d'imprécision &-- &$\surd$ &-- &-- &$\surd$ &-- \\
		Transparence, intelligibilité &-- &-- &-- &$\surd$ &$\surd$ &$\surd$ \\
		%& & & & \\
		%& & & & \\
		
		
	\end{tabular}
\end{center}



\subsubsection{Le cas de la régression linéaire}
On appelle problèmes de régression de tels problèmes, dans lesquels la sortie est numérique, généralement un vecteur de réels, supposé dépendre de la valeur d'un certain nombre de facteurs en entrée \cite{matloff2017statistical,darlington2016regression}.

\begin{figure}[hth]%bth
	\centering
	\includegraphics[width=\textwidth]{images/linear_regression_quartet.png}
	\caption{Images illustrant l'efficacité de la régression linéaire sur plusieurs type de modèle.}
	\label{fig:linear_regression_quartet}
\end{figure}

Le vecteur d'entrée $x = (x_1,x_2,...,x_n)^T$ est souvent appelé variable indépendante, tandis que le vecteur de sortie $y$ est appelé variable dépendante. On formalise le problème en supposant que la sortie résulte de la somme d'une fonction déterministe $f$ de l'entrée et d'un bruit aléatoire :
\begin{equation}
y = f(x) + \epsilon
\end{equation}

où $f(x)$ est la fonction inconnue que nous souhaitons approcher par un estimateur $h(x|w)$, où $h$ est défini à l'aide d'un vecteur $w$ de paramètres \cite{alpaydin2010introduction}.
Si l'on suppose que le bruit $\epsilon$ est nulle et de variance constante $\sigma^2$, c'est-à-dire $ \epsilon = \mathcal{N}(0,\sigma^2)$, alors, en plaçant notre estimateur $h(\cdot)$ à la place de la fonction inconnue, on devrait avoir la densité conditionnelle réelle $p(y|x)$ vérifiant :
\begin{equation}
p(y|x) = \mathcal{N}(h(x|w),\sigma^2)
\end{equation}

On peut estimer le vecteur de paramètres $w$ grâce au principe de maximisation de la vraisemblance. On suppose que les couples $(x_t, y_t)$ de l'échantillon d'apprentissage sont tirés par tirages indépendants d'une distribution de probabilités jointes inconnue $p(x, y)$, qui peut s'écrire :

$$
p(y|x) = p(y|x)p(x)
$$
où $p(y|x)$ est la probabilité de la sortie étant donnée l'entrée et $p(x)$ est la densité de probabilité sur les entrées \cite{matloff2017statistical}.

%Étant donné un échantillon d'apprentissage $S = \langle (x_t,y_t) \rangle_{1\leq t\leq m} $ supposé tiré de manière indépendante et identiquement distribuée.
%Maximiser l'expression résultante revient alors à minimiser la somme de carrés des erreurs (SCE) \cite{antoine2018apprentissage}:
%\begin{equation}\label{eq:sce_1}
%SCE(w|\mathit{S}) = \frac{1}{2} \sum_{{t=1}}^{m}{ [ y_t - h(x_t|w) ]^2}	
%\end{equation}

%%%\subsubsection*{La régression non linéaire ou multiple}


En définissant les vecteurs  et matrice ci dessous, ${\boldsymbol X}$, ${\boldsymbol w}$ et ${\boldsymbol y}$ (avec ${S_y = y}$) \cite{antoine2018apprentissage}; le critère de la somme des carrées des erreurs s'écrit alors:
\begin{equation}\label{eq:sce_2}
SCE(w|\mathit{S}) = \frac{1}{2} ({\boldsymbol S_y }- \mathbf{X}\boldsymbol w)^{\mathsf{T}}({ \boldsymbol S_y }- \mathbf{X} \boldsymbol w)
\end{equation}  
Il suffit de prendre la dérivée de la somme des carrés des erreurs (équation \ref{eq:sce_1}) par rapport à $w$, qui est maintenant remplacer par $w$, pour obtenir les équations: 
$$
\frac{\partial SCE}{\partial w} = -{\boldsymbol X}^T({\boldsymbol S_y }- \mathbf{X} \boldsymbol w)
$$

$$
\frac{\partial^2 SCE}{\partial^2 w \partial^2 w^T} = -{\boldsymbol X}^T{\boldsymbol X}
$$

En supposant que la matrice $X$ est non singulière, et donc que $X^TX$ est positive définie, et en posant que la dérivée première est nulle, on obtient :
\begin{equation}
{X^{T} Xw =  X^{T} S_y}
\end{equation}
à partir de quoi on peut calculer l'unique solution par: 
\begin{equation}
\hat{w} = {(X^{T} X)^{-1} X^{T} S_y}
\end{equation}
La valeur $\hat{y}$ prédite pour une entrée $x_n$ est donc : 
$$
\hat{y} = \hat{w}\cdot x_n = {(X^{T} X)^{-1} X^{T} S_y}x_n 
$$ 


%Un modèle de régression linéaire ajusté peut être utilisé pour identifier la relation entre une seule variable prédictive $x_j$ et la variable de réponse $y$ lorsque toutes les autres variables prédictives du modèle sont "maintenues fixes". Plus précisément, l'interprétation de $\beta_j$ est la variation attendue de $y$ pour une variation d'une unité de $x_j$ lorsque les autres covariables sont maintenues fixes, c'est-à-dire la valeur attendue de la dérivée partielle de $y$ par rapport à $x_j$. Ceci est parfois appelé l'effet unique de $x_j$ sur $y$. En revanche, l'effet marginal de $x_j$ sur $y$ peut être évalué à l'aide d'un coefficient de corrélation ou d'un simple modèle de régression linéaire reliant uniquement $x_j$ à $y$; cet effet est la dérivée totale de $y$ par rapport à $x_j$.



	\subsubsection{Calcul avec l'algorithme du perceptron}

Le premier concept de règle d'apprentissage du perceptron, a été publié par Frank Rosenblatt \cite{antoine2018apprentissage}, basé sur le modèle neuronal MP Neuron (McCulloch-Pitts Neuron). 

%(F. Rosenblatt, The Perceptron, a Perceiving and Recognizing Automaton. Cornell Aeronautical Laboratory, 1957).

Avec sa règle de perceptron, Il a proposé un algorithme qui apprendrait automatiquement les coefficients de poids optimaux qui sont ensuite multipliés par les caractéristiques d'entrée afin de décider si un neurone se déclenche ou non. Dans le cadre de l'apprentissage supervisé et de la classification, un tel algorithme pourrait alors être utilisé pour prédire si un échantillon appartient à une classe ou à l'autre \cite{ml2008python}.

Il est important de noter que la convergence du perceptron n'est garantie que si les deux classes sont linéairement séparables et que le taux d'apprentissage %footenot : taux d'apprentissage definition 
est suffisamment faible. Si les deux classes ne peuvent pas être séparées par une limite de décision linéaire, nous pouvons définir un nombre maximum de passages sur l'ensemble de données d'apprentissage (époques) et/ou un seuil pour le nombre d'erreurs de classification tolérées - le perceptron n'arrêterait jamais de mettre à jour les poids autrement \cite{freund1999large, ml2008python}.

L'algorithme du perceptron travaille directement sur le vecteur a qui caractérise la surface discriminante cherchée. On n'a donc plus besoin ici de se placer dans l'espace de représentation de dimension n+1. Cet algorithme utilise un protocole d'apprentissage itératif : il prend les données d'apprentissage les unes après les autres, chacune étant choisie soit par un passage systématique dans l'ensemble d'apprentissage (version \textit{« non stochastique »}), soit par un tirage au hasard dans celui-ci (version\textit{ « stochastique »}). Son nombre d'étapes effectives peut être important: un seul (exactement ou en moyenne) passage des données n'est en effet pas suffisant pour le faire converger (voir le chapitre \ref{chap:methode}, section \ref{sec:convergence_sgd}). \cite{antoine2018apprentissage}.

%\begin{algorithm}[H]
%	\caption{Perceptron, version stochastique}
%	\begin{algorithmic} 
%		\REQUIRE $n \geq 0 \vee x \neq 0$
%		\STATE $t \leftarrow 0$		
%		\WHILE{$N \neq 0$}
%			\STATE get random $x_i \in X$ set
%			\IF{$x$ is classed}
%				\STATE $a_{t+1} \leftarrow a_t$
%			\ELSE[]
%				\IF{$x \in \mathcal{W}_1$}
%					\STATE	$a_{t+1} \leftarrow a_t + \alpha x$
%				\ELSE[]
%					\STATE	$a_{t+1} \leftarrow a_t - \alpha x$
%				\ENDIF
%				\STATE $t \leftarrow t + 1 $
%			\ENDIF
%		\ENDWHILE		
%	\end{algorithmic}
%\end{algorithm}


\begin{lstlisting}[language=python]
class Perceptron(object):
# Parametres
eta : float # taux d'apprentissage (between 0.0 and 1.0)
n_iter : int # nombre d'iteration
random_state : int # generateur de nombres aleatoires pour l'initialisation de poids aleatoire.
w_ : list # Poids apres fitting.
errors_ : list # Nombre d'erreurs de classification (mises a jour) a chaque epoque.

def __init__(self, eta=0.01, n_iter=50, random_state=1):
self.eta = eta
self.n_iter = n_iter
self.random_state = random_state

# Parameters
X : list, # matrice d'echantillons de taille = (n \times m).
y : list, # vecteur de taille = n, qui contient les valeurs cibles.

def fit(self, X, y): # Ajuster les donnees d'entrainement (Fit training data).
rgen = np.random.RandomState(self.random_state)
self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])
self.errors_ = []

for _ in range(self.n_iter):
errors = 0
for xi, target in zip(X, y):
update = self.eta * (target - self.predict(xi))
self.w_[1:] += update * xi
self.w_[0] += update
errors += int(update != 0.0)
self.errors_.append(errors)
return self

def net_input(self, X): # Calculer la sortie net
return np.dot(X, self.w_[1:]) + self.w_[0]

def predict(self, X):
return np.where(self.net_input(X) >= 0.0, 1, -1)
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CNN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\subsubsection{\qquad \textbullet \ \ Couche de convolution}

La couche de convolution est la pierre angulaire du CNN. Il porte la majeure partie de la charge de calcul du réseau.

Cette couche effectue un produit scalaire entre deux matrices, où une matrice est l'ensemble de paramètres apprenables autrement connu sous le nom de noyau (en anglais kernel) $K$ ou encore filtre de convolution, et l'autre matrice est la partie restreinte du champ récepteur $I$. Le noyau est spatialement plus petit qu'une image mais il est plus en profondeur. Cela signifie que, si l'image est composée de trois canaux (RVB), la hauteur et la largeur du noyau seront spatialement petites, mais la profondeur s'étend jusqu'aux trois canaux \cite{goodfellow2016deep}.

\paragraph*{Définition:}

\textit{Soient $h_1, \ h_2 \in \mathbb{N}, {K} \in \mathbb{R}^{(2h_1+1)\times(2h_2+1)}$. 
	La convolution de $I$ par $K$ est donnée par :} 
\begin{equation} \label{eq:kernel}
(I\ast K)_{r,s} = \sum_{u=-h_1}^{h_1} \sum_{v=-h_2}^{h_2} K_{u,v}I_{r+u,s+v}
\end{equation} 
où $K$ est donnés par : 

$$ 
K = \begin{bmatrix}
{K_{-h_1,-h_2}}&\cdots &{K_{-h_1,h_2}}\\
\vdots &{K_{0,0}} &\vdots \\
{K_{h_1,-h_2}}&\cdots &{K_{h_1,h_2}}
\end{bmatrix}
$$

La taille du filtre $(2h_1+1)\times(2h_2+1)$ précises le champ visuel capturé et traité par $K$.
Lorsque $K$ parcourt $I$, le déplacement du filtre est réglé par deux paramètres de \textit{stride} (horizontal et vertical). Un stride de 1 horizontal (respectivement vertical) signifie que $K$ se déplace d'une position horizontale (resp. verticale) à chaque application de la formule \ref{eq:kernel}. Les valeurs de stride peuvent également être supérieures et ainsi sous-échantillonner $I$ \cite{goodfellow2016deep, antoine2018apprentissage}.\\
Le comportement du filtre sur les bords de $I$ doit également être précisé, par l'intermédiaire d'un paramètre de \textit{padding}. Si l'image convoluée $(I\ast K)$ doit posséder la même taille que $I$, alors $2h_{1}$ lignes de 0 ($h_1$ à gauche et $2h_{1}$ à droite) et $2h_{2}$ colonnes de $0$ ($h_2$ en haut et $h_2$ en bas) doivent être ajoutées. Dans le cas où la convolution est réalisée sans padding, l'image convoluée est de taille $n_{1} - 2h_{1} \times n_{2} - 2h_{2}$ \cite{antoine2018apprentissage}.

%\begin{figure}[H]%bth
%\centering
%\includegraphics[width=0.4\textwidth]{images/cnn_kernel}
%\caption[Illustration des calculs effectués dans une opération de convolution.]{Illustration de l'opération de convolution.}
%	\label{fig:cnn_kernel}
%\end{figure}



%\begin{figure}[H]%bth
%\centering
%\includegraphics[width=\textwidth]{images/image_pixel}
%\caption[Représentation de l'image sous forme de grille de pixels.]{Représentation de l'image sous forme de grille de pixels. Il contient une série de pixels disposés en forme de grille qui contient des valeurs de pixel pour indiquer la luminosité et la couleur de chaque pixel.}
%\label{fig:image_pixel}
%\end{figure}

\begin{figure}[H]%bth
	\centering
	\includegraphics[width=0.8\textwidth]{images/cnn_kernel_filter}
	\caption[Illustration des calculs effectués dans une opération de convolution.]{Illustration des calculs effectués dans une opération de convolution \cite{antoine2018apprentissage}.}
	\label{fig:cnn_kernel_filter}
\end{figure}
%Soit $l$ une couche de convolution. L'entrée de la couche $l$ est composée de $n ^ {(l - 1)}$ cartes provenant de la couche précédente, de taille $n_{1} ^ {(l - 1)} * n_{2} ^ {(l - 1)}$. Dans le cas de la rétine $(l = 1)$ l'entrée est l'image $I$. La sortie de la couche $l$ est formée de $n ^ {(l)}$ cartes de taille $n_1 ^ {(l)} \times n_2 ^ {(l)}$. La $i^e$ cartes de la couche $l$ notée $Y_{i} ^ {(l)}$ se calcule comme:

%\begin{equation}
%	\qquad	Y_i ^ {(l)} =B_i ^ {(l)} + \sum_{j=1}^{n^{(l-1)}} K_{i,j}^{(l)} \ast Y_j^{(l-1)}
%\end{equation}

%où $B^{()}$ est une matrice de biais et $K_{i,j}^{(l)}$ est le filtre de taille $(2h_1^{(l)}+1)\times(2h_2^{(l)}+1)$ connectant la $j^e$ carte de la couche $(l-1)$ à la $i^e$ carte de la couche $l$.

%$n_{1} ^ {(l)} $ et $ n_{2} ^ {(l)}$ doivent prendre en compte les effets de bords: lors du calcul de la convolution, seuls les pixels dont la somme est définie avec des indices positifs doivent être traités. Dans le cas où le padding n'est pas utilisé, les cartes de sortie ont donc une taille de $n_{1} ^ {(l)} = n_{1} ^ {(l-1)} - 2h_1 ^ {(l)} $ et $ n_{2} ^ {(l)} = n_{2} ^ {(l-1)} - 2h_2 ^ {(l)}$.

Par conséquent, la couche de convolution prend plusieurs images en entrée  et utilise chaque filtre pour calculer la convolution de  chaque image. Le filtre correspond exactement à la caractéristique que nous voulons trouver dans l'image \cite{shin2016deep}. 
Pour chaque paire (image, filtre), obtenez une carte d'activation ou une carte d'entités montrant où se trouvent les entités dans l'image. Plus la valeur est élevée, plus les points correspondants dans l'image sont similaires à l'entité \cite{goodfellow2016deep}.

%Souvent, les filtres utilisés pour calculer $Y_i ^ {(l)}$ sont les mêmes. De plus, la somme dans l'équation (10.3) peut être conduite sur un sous ensemble des cartes d'entrée.


\subsubsection*{\qquad \textbullet \ \ Couche non linéaire}

Pour augmenter le pouvoir d'expression des réseaux profonds, on utilise couches non linéaires\cite{antoine2018apprentissage}.
Étant donné que la convolution est une opération linéaire et que les images sont loin d'être linéaires, les couches de non-linéarité sont souvent placées directement après la couche de convolution pour introduire la non-linéarité dans la carte d'activation \cite{goodfellow2016deep}.

Trois grandes classes de fonctions d'activation $f$ sont généralement utilisées : les fonctions de seuils (comme dans le perceptron linéaire à seuil), les fonctions linéaires par morceaux (ReLU : voir le la section \ref{sec:activation_weight}, point \ref{subsec:relu} ) et les fonctions de type sigmoïde \cite{goodfellow2016deep}. Dans les deux premiers cas, de nombreux problèmes se présentent, notamment en raison de la non différentiabilité de ces fonctions (qui est nécessaire dans les algorithmes d'apprentissage du type descente de gradient), ou encore en raison de la faiblesse de leur pouvoir d'expression. Ainsi, il est préférable d'utiliser des fonctions de type sigmoïde \cite{antoine2018apprentissage}.


\subsubsection*{\qquad \textbullet \ \ Couche de regroupement (Pooling)}
Ce type de couche est souvent placé entre deux couches de convolution : elle reçoit en entrée plusieurs feature maps, et applique à chacune d'entre elles l'opération de pooling\footnote{L'opération de pooling consiste à réduire la taille des images, tout en préservant leurs caractéristiques importantes.}. La couche de regroupement remplace la sortie du réseau à certains emplacements en dérivant une statistique récapitulative des sorties à proximité. Cela aide à réduire la taille spatiale de la représentation, ce qui diminue la quantité requise de calculs et de pondérations. L'opération de regroupement est traitée sur chaque tranche de la représentation individuellement \cite{goodfellow2016deep}. 

Tout comme dans les couches conventionnelles, chaque neurone d'une couche de regroupement est connecté aux sorties d'un nombre limité de neurones de la couche précédente, situés dans un petit champ récepteur rectangulaire. Vous devez définir sa taille, la foulée et le type de rembourrage, comme avant. Cependant, un neurone de regroupement n'a pas de poids; tout ce qu'il fait est d'agréger les entrées à l'aide d'une fonction d'agrégation telle que le max ou la moyenne \cite{geron2017hands}.

\begin{figure}[H]%bth
	\centering
	\includegraphics[width=\textwidth]{images/cnn_complet}
	\caption{Illustration de l'architecture d'un CNN.}
	\label{fig:cnn_complet}
\end{figure}

Il existe plusieurs fonctions de regroupement telles que la moyenne du voisinage rectangulaire, la norme L2 du voisinage rectangulaire et une moyenne pondérée basée sur la distance par rapport au pixel central. Cependant, le processus le plus populaire est la mise en commun maximale, qui signale la sortie maximale du voisinage \cite{goodfellow2016deep}.

Le regroupement (pooling) des cartes obtenues par les couches précédentes a pour objectif d'assurer une robustesse au bruit et aux distorsions.\\
La sortie d'une couche d'agrégation est composée de $n^{(l)} = n^{(l - 1)}$ cartes de taille réduite. En général, le pooling est effectuée en déplaçant dans les cartes d'entrée une fenêtre de taille $2p * 2p$ toutes les $q$ positions, il y a recouvrement si $q < p$ et non recouvrement sinon, et en calculant, pour chaque position de la fenêtre, une seule valeur, affectée à la position centrale dans la carte de sortie \cite{antoine2018apprentissage}. On distingue généralement deux types de pooling:

\begin{list}{--}{}
	\item La moyenne : on utilise un filtre $K_{B}$ de taille $(2h_{1} + 1)(2h_{2} + 1)$.
	\item Le maximum : la valeur maximum dans la fenêtre est retenue. Le maximum est souvent utilisé pour assurer une convergence rapide durant la phase d'entraînement. Le pooling avec recouvrement, il, semble assurer une réduction du phénomène de surapprentissage \cite{antoine2018apprentissage}.  
\end{list}




\subsubsection*{\qquad \textbullet \ \ Couche entièrement connectée (fully-connected)}

La couche entièrement connectée constitue toujours la dernière couche d'un réseau de neurones, convolutif ou non, elle n'est donc pas caractéristique d'un CNN. 

Les neurones de cette couche ont une connectivité complète avec tous les neurones de la couche précédente et suivante, comme on peut le voir dans un FCNN (Fully Convolutional Neural Network) normal. C'est pourquoi il peut être calculé comme d'habitude par une multiplication matricielle suivie d'un effet de biais. La couche fully-connected aide à mapper la représentation entre l'entrée et la sortie \cite{goodfellow2016deep}.

Ce type de couche reçoit un vecteur en entrée et produit un nouveau vecteur en sortie. Pour cela, elle applique une combinaison linéaire puis éventuellement une fonction d'activation aux valeurs reçues en entrée.

La couche entièrement connectée détermine le lien entre la position des features dans l'image et une classe. En effet, le tableau en entrée étant le résultat de la couche précédente, il correspond à une carte d'activation pour une feature donnée : les valeurs élevées indiquent la localisation (plus ou moins précise selon le pooling) de cette feature dans l'image. Si la localisation d'une feature à un certain endroit de l'image est caractéristique d'une certaine classe, alors on accorde un poids important à la valeur correspondante dans le tableau \cite{shin2016deep}.

\begin{figure}[H]%bth
	\centering
	\includegraphics[width=0.8\textwidth]{images/cnn_image1}
	\caption{Illustration d'un CNN montrant les différentes couches.}
	\label{fig:cnn_}
\end{figure}






%########################################################################
%
%########################################################################









%########################################################################
%
%########################################################################









%########################################################################
%
%########################################################################









%########################################################################
%
%########################################################################