

\textcolor{cyan}{\chapter{Introduction}}
	\section{Choix et intérêt du sujet}
	
		L’intelligence désigne communément le potentiel des capacités mentales et cognitives d'un individu, animal ou humain, lui permettant de résoudre un problème ou de s'adapter à son environnement. L'intelligence nous fait ressentir ce besoin d’apprendre pour arriver à nos fins, extresinquement l'intelligence c’est l'apprentissage. Pour que nous puissions dire qu’une machine est intelligente, premièrement elle doit passer par une phase d'apprentissage.  Apprendre à résoudre des problèmes ou à réaliser des tâches par lui-même d’une façon autonome. Dans le IA nous parlons de l’apprentissage automatique (en anglais: machine Learning, ML), nous utilisons plusieurs paradigmes d’apprentissage automatique:  apprentissage supervisé, apprentissage non supervisé, apprentissage par renforcement, apprentissage en profondeur.
		
		L'apprentissage supervisé représente une grande partie de l'activité de recherche en apprentissage automatique et de nombreuses techniques de ce paradigme ont trouvé une application dans le traitement de contenu multimédia \cite{cunningham2008supervised}. La caractéristique qui définit ce type d’apprentissage est la disponibilité de données d'apprentissage annotées.\\ Les algorithmes d'apprentissage supervisé font l'expérience d'un ensemble de données contenant des caractéristiques, et chaque exemple est également associé à une étiquette ou à une cible \cite{goodfellow2016deep}. 
		
		L’application de cette étude dans l’apprentissage supervisé est orientée vers la reconnaissance automatique des plaques d’immatriculation (en anglais: \t{automatic number plate recognition, ANPR}) dans les images. Une des applications intéressantes parmi tant d'autres dans l'intelligence artificielle. Nous présentons une étude approfondie sur les algorithmes de minimisation de la fonction coût (en anglais : loss function) d’un modèle d’apprentissage appliqué à l'ANPR. 
		
		Lorsque nous voulons faire une application dans le traitement de reconnaissance des formes dans des vidéos, les ensembles de données d'entraînement pour les  problèmes de détection d'objets sont généralement très volumineux et les capacités des méthodes d'apprentissage automatique statistique sont limitées par le temps de calcul plutôt que par la taille de l'échantillon \cite{bottou2010large}.
		Par exemple, pour entraîner une machine à reconnaître des plaques d'immatriculation de voiture, elle doit recevoir de grandes quantités d'images de plaques d'immatriculation et d'éléments liés aux plaques pour apprendre les différences et reconnaître une plaque, en particulier la voiture qui porte une plaque sans défaut. Plus nous avons des données, plus nous gagnons en précision et plus la complexité en temps augmente.\\
		Des contraintes d'exploitation découlent des observations citées ci-dessus, parmi lesquelles nous citerons celles qui sont liées à la reconnaissance des objets dans les vidéos et images. Par exemple, de nos jours, un très grand nombre de caméras est déployé exclusivement pour la surveillance vidéo \cite{ahadjitse2013reconnaissance} . Souvent, le contenu de ces vidéos est interprété par des opérateurs humains qui engendrent des coûts exorbitants pour le suivi et l'analyse du contenu, sans mentionner les erreurs qui peuvent être induites par la fatigue et l'inattention humaine. 
		
		
		
	
	\section{Problématique}
		La complexité de calcul de l'algorithme d'apprentissage devient le facteur limitant critique lorsque l'on envisage de très grands ensembles de données. C'est à ce point critique qu'entre en jeu cette étude, la minimisation des erreurs sans alourdir la complexité en temps et espace de l’algorithme d’apprentissage. 
		
		Les ensembles de données d'entraînement pour les problèmes de détection d'objets dans des images sont généralement très volumineux. Minimiser les erreurs dans ces modèles d’apprentissage est une tâche très importante pour renforcer la fiabilité de notre \emph{modèle entraîné} \cite{ibm2018ml}.\\
		Établir un algorithme d’apprentissage qui s'adapte au mieux à notre modèle, selon la nature du problème métier traité, il existe différentes approches qui varient selon le type et le volume des données.
		
		L'un des piliers de l'apprentissage automatique est l'optimisation mathématique \cite{bottou2018optimization}, qui, dans ce contexte, implique le calcul numérique de minimisation des paramètres d'un système conçu pour prendre des décisions en fonction des données disponibles. Ces paramètres sont choisis pour être optimaux par rapport à notre problème d'apprentissage.
		
		Dans l'ensemble, ce document tente d'apporter des réponses aux questions suivantes.
		\begin{enumerate}
			\item Comment les problèmes de minimisation surviennent-ils dans les applications d'apprentissage automatique ?
			\item Quelles ont été les méthodes de minimisation les plus efficaces pour les ensembles des données d'apprentissage supervisé à grande échelle et pourquoi ?
			\item Comment des algorithmes d'apprentissage supervisé arrivent-t-ils résoudre le problème de la reconnaissance automatique d'objet ?
			\item Quelles avancées récentes ont été réalisées dans la conception d'algorithmes de minimisation des erreurs dans l'apprentissage et quelles sont les questions ouvertes dans ce domaine de recherche ?
		\end{enumerate}
	
	\section{Hypothèse}
		Le cas des problèmes d'apprentissage à grande ou à petite échelle implique la complexité de calcul de l'algorithme d'optimisation sous-jacent de manière non triviale.\\
		En effet, dans ce travail, nous discutons des algorithmes de descente de gradient stochastique parce qu’ils montrent des performances d'optimisation incroyables pour les problèmes à grande échelle \cite{bottou2010large}. 
		
		Le travail de Léon Bottou et al (\eg, dans \cite{bottou2010large} \cite{wijnhoven2010fast} \cite{bottou2012stochastic} ), présente \textit{la descente de gradient stochastique comme un algorithme d'apprentissage fondamental.}\\
		Une analyse plus précise révèle des compromis qualitativement différents pour le cas des problèmes d'apprentissage à grande échelle \cite{bottou2018optimization}. Des algorithmes d'optimisation improbables tels que la \textbf{descente de gradient stochastique} (en anglais: \textbf{Stochastic Gradient Descent} ou SGD) montre des performances étonnantes pour les problèmes à grande échelle, lorsque l'ensemble d'apprentissage est volumineux. En particulier, le gradient stochastique du second ordre et le gradient stochastique moyennée sont asymptotiquement efficaces après un seul passage sur l' ensemble d'entraînement \cite{bottou2010large}. Les optimiseurs SGD n'utilisent qu'un seul nouvel échantillon d'apprentissage à chaque itération.
		
		
			
	\section{État de l'art}
	
	\section{Objectifs et division du travail}
		
		Nous nous proposons dans ce mémoire d'aborder sur l'utilisation des algorithmes d'optimisation numérique, précisément de minimisation. Appliquée à l'apprentissage automatique qui permet aux ordinateurs et aux systèmes informatiques de dériver des informations significatives à partir d'images numériques et/ou d'autres entrées visuelles, avec un coût plus bas que possible.  
		
		En fait, nous faisons la reconnaissance des plaques d’immatriculation des véhicules à l'aide d’un classificateur de la famille de descente de gradient stochastique (SGD). Pour minimiser la fonction de coût du classificateur, la SGD adopte un modèle d'optimisation convexe \cite{deepa2021ai}. De plus, pour augmenter la vitesse de convergence du classificateur, la descente de gradient stochastique, à chaque étape, tire un échantillon aléatoire de l'ensemble des fonctions ($f_i$), qui est notre fonction objectif, constituant une somme.\\
		Pour chaque algorithme, nous examinons l'efficacité et comparons le score pour différents cas.
		
		\begin{list}{}{En dehors de cette introduction, la partie conclusive et l'annexe, ce mémoire est organisé en quatre chapitres comme suit.}
			\item \textbf{\textsl{\texttt{Chapitre 1}}} est consacré à quelques rappels des matières sur lesquels je me base pour constituer l'ensemble de ce travail.  Nous traitons des considérations de méthodes numériques impliquées dans la résolution de problèmes de minimisation des erreurs d’apprentissage. Certaines discussions sur les modèles de régression linéaire convexe et de classification dans d’apprentissage supervisé. Nous discutons également du réseau neuronal convolutif le plus adapté pour analyser l'imagerie visuelle.
			
			\item \textbf{\textsl{\texttt{Chapitre 2}}} explore une méthodologie parmi tant d’autres, pour entraîner les modèles d’apprentissage automatique de façon optimale, qui nous permettra par la suite de faire une classification d’images pour reconnaissance automatique de plaque d'immatriculation.\\
			Pour la minimisation de la fonction coût nous utilisons des algorithmes comme ASGD, ADAM, ADADELTA, NAG. Puis faire une étude comparative de leurs performances. 
			
			\item \textbf{\textsl{\texttt{Chapitre 3}}}, Ici nous construirons des modèles à partir d’une base de données annotée pour l'apprentissage et pour les tests de reconnaissance d'objets. Les résultats concluants de cette étude pourront conduire à un déploiement de notre système dans les domaines comme  celui de la surveillance vidéo de voitures dans une entrée de parking. Des métriques connues pour mesurer les erreurs et en déduire le score du classificateur seront utilisées pour évaluer la qualité de la reconnaissance automatique des plaques d’immatriculation (ANPR) par notre approche.
		\end{list}
	
	

		
		
		
		